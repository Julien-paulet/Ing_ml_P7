{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from transformers import TFBertModel,  BertConfig, BertTokenizer, AutoModel, PreTrainedTokenizerFast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unstemmed_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs cakephp vs zend vs cakephp vs zend cakephp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tools generating mock data tools generating mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laravel use statement non name cache effect la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add client authentication add client authentic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>variable error variable error system namespace...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      unstemmed_desc\n",
       "0  vs cakephp vs zend vs cakephp vs zend cakephp ...\n",
       "1  tools generating mock data tools generating mo...\n",
       "2  laravel use statement non name cache effect la...\n",
       "3  add client authentication add client authentic...\n",
       "4  variable error variable error system namespace..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data_cleaned.csv',\n",
    "                   converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "\n",
    "dataset = dataset[['unstemmed_desc']].dropna()\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(r'pandas.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"pandas.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://arxiv.org/abs/1508.07909 <br/>\n",
    "https://huggingface.co/blog/how-to-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=path, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer you trained\n",
    "tokenizer.save(\"byte-level-BPE.tokenizer.json\")\n",
    "\n",
    "# Load it using transformers\n",
    "tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"byte-level-BPE.tokenizer.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a standard Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the randomness\n",
    "from numpy.random import seed\n",
    "seed(1337)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalStrategy = \"retrain\" # Either retrain or keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data, predict):\n",
    "    f1 = []\n",
    "    jaccard = []\n",
    "    threshold = []\n",
    "    for i in np.arange(0.30, 0.99, 0.01):\n",
    "        predict_ = np.where(predict >= i, 1, 0)\n",
    "        f1_micro = metrics.f1_score(data, predict_, average = 'micro')\n",
    "        jaccard_micro = metrics.jaccard_score(data, predict_, average = 'micro')\n",
    "        f1.append(f1_micro)\n",
    "        jaccard.append(jaccard_micro)\n",
    "        threshold.append(i)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['Threshold'] = threshold\n",
    "    results['F1_micro'] = f1\n",
    "    results['Jaccard_micro'] = jaccard\n",
    "    results = results[results['F1_micro'] == results['F1_micro'].max()]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>unstemmed_desc</th>\n",
       "      <th>preprocessedTags</th>\n",
       "      <th>Tag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vs cakephp vs zend vs cakephp vs zend cakephp ...</td>\n",
       "      <td>vs cakephp vs zend vs cakephp vs zend cakephp ...</td>\n",
       "      <td>[php]</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tool generat mock data tool generat mock data ...</td>\n",
       "      <td>tools generating mock data tools generating mo...</td>\n",
       "      <td>[testing]</td>\n",
       "      <td>testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laravel use statement non name cach effect lar...</td>\n",
       "      <td>laravel use statement non name cache effect la...</td>\n",
       "      <td>[php, laravel]</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>add client authent add client authent server r...</td>\n",
       "      <td>add client authentication add client authentic...</td>\n",
       "      <td>[java]</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>variabl error variabl error system namespac cl...</td>\n",
       "      <td>variable error variable error system namespace...</td>\n",
       "      <td>[c#]</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  \\\n",
       "0  vs cakephp vs zend vs cakephp vs zend cakephp ...   \n",
       "1  tool generat mock data tool generat mock data ...   \n",
       "2  laravel use statement non name cach effect lar...   \n",
       "3  add client authent add client authent server r...   \n",
       "4  variabl error variabl error system namespac cl...   \n",
       "\n",
       "                                      unstemmed_desc preprocessedTags     Tag1  \n",
       "0  vs cakephp vs zend vs cakephp vs zend cakephp ...            [php]      php  \n",
       "1  tools generating mock data tools generating mo...        [testing]  testing  \n",
       "2  laravel use statement non name cache effect la...   [php, laravel]      php  \n",
       "3  add client authentication add client authentic...           [java]     java  \n",
       "4  variable error variable error system namespace...             [c#]       c#  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_cleaned.csv',\n",
    "                   converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "#data = pd.read_csv('data_cleaned2.csv',\n",
    "#                   converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "\n",
    "data = data[['desc', 'unstemmed_desc', 'preprocessedTags', 'Tag1']].dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['desc']\n",
    "x_unstemmed = data['unstemmed_desc']\n",
    "y = data['preprocessedTags']\n",
    "# y_tag = data['Tag1']\n",
    "mb = MultiLabelBinarizer()\n",
    "y_encoded = mb.fit_transform(y)\n",
    "# y_encoded = mb.fit_transform(y_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_unstemmed,\n",
    "                                                    y_encoded,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready output data for the model\n",
    "max_length=250\n",
    "\n",
    "x_train_toke = tokenizer(text=x_train.to_list(),\n",
    "                         add_special_tokens=True,\n",
    "                         max_length=max_length,\n",
    "                         truncation=True,\n",
    "                         padding=True, \n",
    "                         return_tensors='tf',\n",
    "                         return_token_type_ids=False,\n",
    "                         return_attention_mask=False,\n",
    "                         verbose=True)\n",
    "\n",
    "x_test_toke = tokenizer(text=x_test.to_list(),\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='tf',\n",
    "                        return_token_type_ids=False,\n",
    "                        return_attention_mask=False,\n",
    "                        verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_toke = x_train_toke['input_ids']\n",
    "x_test_toke = x_test_toke['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xInput = Input(shape=(max_length))\n",
    "x_ = Dense(500, activation='relu')(xInput)\n",
    "x_ = Dense(500, activation='relu')(x_)\n",
    "output = Dense(len(y_encoded[0]), activation='sigmoid')(x_)\n",
    "\n",
    "personalizedTokenizer = Model(inputs=xInput, outputs=output, name='Baseline')\n",
    "\n",
    "# Compile the model\n",
    "personalizedTokenizer.compile(loss=CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "                              optimizer=Adam(learning_rate=0.0000001),\n",
    "                              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=10,\n",
    "                                            mode='max',\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Baseline\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 500)               125500    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 206)               103206    \n",
      "=================================================================\n",
      "Total params: 479,206\n",
      "Trainable params: 479,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "personalizedTokenizer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 24150.6981 - acc: 0.0034 - val_loss: 21661.8906 - val_acc: 0.0112\n",
      "Epoch 2/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 20465.6975 - acc: 0.0153 - val_loss: 18874.5469 - val_acc: 0.0133\n",
      "Epoch 3/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 17780.6495 - acc: 0.0134 - val_loss: 16777.2793 - val_acc: 0.0149\n",
      "Epoch 4/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 15995.9154 - acc: 0.0162 - val_loss: 14985.4551 - val_acc: 0.0149\n",
      "Epoch 5/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 14272.8255 - acc: 0.0173 - val_loss: 13607.1904 - val_acc: 0.0186\n",
      "Epoch 6/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 12887.0171 - acc: 0.0205 - val_loss: 12529.1172 - val_acc: 0.0276\n",
      "Epoch 7/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 12057.5945 - acc: 0.0270 - val_loss: 11778.8301 - val_acc: 0.0337\n",
      "Epoch 8/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 11360.5377 - acc: 0.0283 - val_loss: 11108.6494 - val_acc: 0.0290\n",
      "Epoch 9/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 10725.2225 - acc: 0.0293 - val_loss: 10542.9229 - val_acc: 0.0282\n",
      "Epoch 10/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 10183.9948 - acc: 0.0287 - val_loss: 10033.0830 - val_acc: 0.0305\n",
      "Epoch 11/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 9683.4813 - acc: 0.0312 - val_loss: 9559.5303 - val_acc: 0.0324\n",
      "Epoch 12/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 9293.6305 - acc: 0.0303 - val_loss: 9132.2510 - val_acc: 0.0308\n",
      "Epoch 13/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 8845.5304 - acc: 0.0301 - val_loss: 8754.6436 - val_acc: 0.0316\n",
      "Epoch 14/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 8517.9268 - acc: 0.0322 - val_loss: 8431.2930 - val_acc: 0.0332\n",
      "Epoch 15/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 8180.6375 - acc: 0.0346 - val_loss: 8242.5820 - val_acc: 0.0367\n",
      "Epoch 16/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 8077.4036 - acc: 0.0375 - val_loss: 8126.4854 - val_acc: 0.0364\n",
      "Epoch 17/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7990.8348 - acc: 0.0395 - val_loss: 8020.0957 - val_acc: 0.0390\n",
      "Epoch 18/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7786.5334 - acc: 0.0393 - val_loss: 7915.1772 - val_acc: 0.0396\n",
      "Epoch 19/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7713.2554 - acc: 0.0405 - val_loss: 7815.8838 - val_acc: 0.0396\n",
      "Epoch 20/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7650.4888 - acc: 0.0384 - val_loss: 7724.7891 - val_acc: 0.0396\n",
      "Epoch 21/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7521.6710 - acc: 0.0388 - val_loss: 7635.0244 - val_acc: 0.0390\n",
      "Epoch 22/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7453.3952 - acc: 0.0389 - val_loss: 7555.2554 - val_acc: 0.0388\n",
      "Epoch 23/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7352.8845 - acc: 0.0397 - val_loss: 7477.1592 - val_acc: 0.0388\n",
      "Epoch 24/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7305.0317 - acc: 0.0393 - val_loss: 7411.5142 - val_acc: 0.0385\n",
      "Epoch 25/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7297.8961 - acc: 0.0400 - val_loss: 7341.0938 - val_acc: 0.0377\n",
      "Epoch 26/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7203.8494 - acc: 0.0389 - val_loss: 7280.3101 - val_acc: 0.0388\n",
      "Epoch 27/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7104.6192 - acc: 0.0386 - val_loss: 7225.1167 - val_acc: 0.0390\n",
      "Epoch 28/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7065.5213 - acc: 0.0393 - val_loss: 7175.1172 - val_acc: 0.0398\n",
      "Epoch 29/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 7002.5237 - acc: 0.0407 - val_loss: 7129.7324 - val_acc: 0.0396\n",
      "Epoch 30/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6939.9133 - acc: 0.0390 - val_loss: 7086.6914 - val_acc: 0.0388\n",
      "Epoch 31/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6995.5738 - acc: 0.0404 - val_loss: 7050.8276 - val_acc: 0.0375\n",
      "Epoch 32/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6924.6246 - acc: 0.0396 - val_loss: 7018.6055 - val_acc: 0.0377\n",
      "Epoch 33/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6859.3530 - acc: 0.0389 - val_loss: 6987.7026 - val_acc: 0.0369\n",
      "Epoch 34/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6846.7782 - acc: 0.0397 - val_loss: 6963.7842 - val_acc: 0.0375\n",
      "Epoch 35/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6753.2137 - acc: 0.0398 - val_loss: 6938.9736 - val_acc: 0.0372\n",
      "Epoch 36/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6798.0431 - acc: 0.0419 - val_loss: 6923.9785 - val_acc: 0.0380\n",
      "Epoch 37/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6774.8403 - acc: 0.0423 - val_loss: 6912.2886 - val_acc: 0.0390\n",
      "Epoch 38/200\n",
      "1059/1059 [==============================] - 2s 2ms/step - loss: 6847.0231 - acc: 0.0411 - val_loss: 6904.4355 - val_acc: 0.0385\n",
      "INFO:tensorflow:Assets written to: /home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/assets\n"
     ]
    }
   ],
   "source": [
    "# Load the baseline, if does not exist then train one\n",
    "if globalStrategy == 'retrain' or globalStrategy == 'retrainPersonalizedTokenizer':\n",
    "    epochs = epochs\n",
    "    batch_size=batch_size\n",
    "    history = personalizedTokenizer.fit(x_train_toke, y_train,\n",
    "                                        epochs=epochs,\n",
    "                                        validation_split=0.1,\n",
    "                                        callbacks=[callback],\n",
    "                                        verbose=1)\n",
    "\n",
    "    personalizedTokenizer.save('/home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/')\n",
    "    personalizedTokenizer = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/')\n",
    "else:\n",
    "    try:\n",
    "        personalizedTokenizer = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/')\n",
    "    except OSError:\n",
    "        epochs = epochs\n",
    "        batch_size=batch_size\n",
    "        history = personalizedTokenizer.fit(x_train_toke, y_train,\n",
    "                                            epochs=epochs,\n",
    "                                            validation_split=0.1,\n",
    "                                            callbacks=[callback],\n",
    "                                            verbose=1)\n",
    "\n",
    "        personalizedTokenizer.save('/home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/')\n",
    "        personalizedTokenizer = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/personalizedTokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295/295 [==============================] - 0s 1ms/step - loss: 7043.7266 - acc: 0.0400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7043.7265625, 0.03995324671268463]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "personalizedTokenizer.evaluate(x_test_toke, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = personalizedTokenizer.predict(x_test_toke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>Jaccard_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.98</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  F1_micro  Jaccard_micro\n",
       "68       0.98  0.021899       0.011071"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict_ = np.where(predict>0.55, 1, 0)\n",
    "scoring(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 1., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 0., 1.,\n",
       "       0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read msg files read msg files need read outlook msg file net without com api outlook cos installed machines app run free 3rd party libraries want extract cc fields sent receive date fields would good also stored msg files\n",
      "['read', 'Ġmsg', 'Ġfiles', 'Ġread', 'Ġmsg', 'Ġfiles', 'Ġneed', 'Ġread', 'Ġoutlook', 'Ġmsg', 'Ġfile', 'Ġnet', 'Ġwithout', 'Ġcom', 'Ġapi', 'Ġoutlook', 'Ġcos', 'Ġinstalled', 'Ġmachines', 'Ġapp', 'Ġrun', 'Ġfree', 'Ġ3', 'rd', 'Ġparty', 'Ġlibraries', 'Ġwant', 'Ġextract', 'Ġcc', 'Ġfields', 'Ġsent', 'Ġreceive', 'Ġdate', 'Ġfields', 'Ġwould', 'Ġgood', 'Ġalso', 'Ġstored', 'Ġmsg', 'Ġfiles']\n",
      "tf.Tensor(\n",
      "[10192  1663  1574   479   479   568  3844  1663  1574   479   479   568\n",
      "  1121  9203  1574  1643   568  2474   584   417   454  1663  1574   479\n",
      "   479  1967  1574   576  1168  2147  1035   289   526   289   526   289\n",
      "   526  1039  8172   289  1942  1942   454  1092   575  1574   636   723\n",
      "  1092  1092  1092   636   636   723   408  1092  1574   636   408  5890\n",
      "  1043  1574   636  1043  1092  1574  1043   723  1092  5890  1342   408\n",
      "  5890 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623\n",
      " 13623 13623 13623 13623 13623 13623 13623 13623 13623 13623], shape=(250,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[15])\n",
    "print(tokenizer.tokenize(x_train[15]))\n",
    "print(x_train_toke[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain Partially a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
