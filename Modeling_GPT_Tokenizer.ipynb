{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import OpenAIGPTTokenizer, TFOpenAIGPTModel\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the randomness\n",
    "from numpy.random import seed\n",
    "seed(1337)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalStrategy = \"retrain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(data, predict):\n",
    "    f1 = []\n",
    "    jaccard = []\n",
    "    threshold = []\n",
    "    for i in np.arange(0.30, 0.99, 0.01):\n",
    "        predict_ = np.where(predict >= i, 1, 0)\n",
    "        f1_micro = metrics.f1_score(data, predict_, average = 'micro')\n",
    "        jaccard_micro = metrics.jaccard_score(data, predict_, average = 'micro')\n",
    "        f1.append(f1_micro)\n",
    "        jaccard.append(jaccard_micro)\n",
    "        threshold.append(i)\n",
    "    \n",
    "    results = pd.DataFrame()\n",
    "    results['Threshold'] = threshold\n",
    "    results['F1_micro'] = f1\n",
    "    results['Jaccard_micro'] = jaccard\n",
    "    results = results[results['F1_micro'] == results['F1_micro'].max()]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>desc</th>\n",
       "      <th>unstemmed_desc</th>\n",
       "      <th>preprocessedTags</th>\n",
       "      <th>Tag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591865</td>\n",
       "      <td>vs cakephp vs zend vs cakephp vs zend cakephp ...</td>\n",
       "      <td>vs cakephp vs zend vs cakephp vs zend cakephp ...</td>\n",
       "      <td>[php]</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>591892</td>\n",
       "      <td>tool generat mock data tool generat mock data ...</td>\n",
       "      <td>tools generating mock data tools generating mo...</td>\n",
       "      <td>[testing]</td>\n",
       "      <td>testing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41441462</td>\n",
       "      <td>laravel use statement non name cach effect lar...</td>\n",
       "      <td>laravel use statement non name cache effect la...</td>\n",
       "      <td>[php, laravel]</td>\n",
       "      <td>php</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9552725</td>\n",
       "      <td>add client authent add client authent server r...</td>\n",
       "      <td>add client authentication add client authentic...</td>\n",
       "      <td>[java]</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33014984</td>\n",
       "      <td>variabl error variabl error system namespac cl...</td>\n",
       "      <td>variable error variable error system namespace...</td>\n",
       "      <td>[c#]</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47050</th>\n",
       "      <td>18363295</td>\n",
       "      <td>jqueri event child jqueri event child anchor w...</td>\n",
       "      <td>jquery event child jquery event child anchor w...</td>\n",
       "      <td>[javascript, jquery]</td>\n",
       "      <td>javascript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47051</th>\n",
       "      <td>18363308</td>\n",
       "      <td>best way remov word best way remov word strong...</td>\n",
       "      <td>best way remove words best way remove words st...</td>\n",
       "      <td>[c#, winforms]</td>\n",
       "      <td>c#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47052</th>\n",
       "      <td>8625692</td>\n",
       "      <td>array output array output includ main 3 b 6 pr...</td>\n",
       "      <td>array output array output include main 3 b 6 p...</td>\n",
       "      <td>[c]</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47053</th>\n",
       "      <td>19723361</td>\n",
       "      <td>ok pointer invalid locat use ok pointer invali...</td>\n",
       "      <td>ok pointer invalid location use ok pointer inv...</td>\n",
       "      <td>[c]</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47054</th>\n",
       "      <td>25303563</td>\n",
       "      <td>make circular menu make circular menu current ...</td>\n",
       "      <td>making circular menu making circular menu curr...</td>\n",
       "      <td>[android, android-layout, user-interface]</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47055 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                                               desc  \\\n",
       "0        591865  vs cakephp vs zend vs cakephp vs zend cakephp ...   \n",
       "1        591892  tool generat mock data tool generat mock data ...   \n",
       "2      41441462  laravel use statement non name cach effect lar...   \n",
       "3       9552725  add client authent add client authent server r...   \n",
       "4      33014984  variabl error variabl error system namespac cl...   \n",
       "...         ...                                                ...   \n",
       "47050  18363295  jqueri event child jqueri event child anchor w...   \n",
       "47051  18363308  best way remov word best way remov word strong...   \n",
       "47052   8625692  array output array output includ main 3 b 6 pr...   \n",
       "47053  19723361  ok pointer invalid locat use ok pointer invali...   \n",
       "47054  25303563  make circular menu make circular menu current ...   \n",
       "\n",
       "                                          unstemmed_desc  \\\n",
       "0      vs cakephp vs zend vs cakephp vs zend cakephp ...   \n",
       "1      tools generating mock data tools generating mo...   \n",
       "2      laravel use statement non name cache effect la...   \n",
       "3      add client authentication add client authentic...   \n",
       "4      variable error variable error system namespace...   \n",
       "...                                                  ...   \n",
       "47050  jquery event child jquery event child anchor w...   \n",
       "47051  best way remove words best way remove words st...   \n",
       "47052  array output array output include main 3 b 6 p...   \n",
       "47053  ok pointer invalid location use ok pointer inv...   \n",
       "47054  making circular menu making circular menu curr...   \n",
       "\n",
       "                                preprocessedTags        Tag1  \n",
       "0                                          [php]         php  \n",
       "1                                      [testing]     testing  \n",
       "2                                 [php, laravel]         php  \n",
       "3                                         [java]        java  \n",
       "4                                           [c#]          c#  \n",
       "...                                          ...         ...  \n",
       "47050                       [javascript, jquery]  javascript  \n",
       "47051                             [c#, winforms]          c#  \n",
       "47052                                        [c]           c  \n",
       "47053                                        [c]           c  \n",
       "47054  [android, android-layout, user-interface]     android  \n",
       "\n",
       "[47055 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data_cleaned.csv',\n",
    "                   converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "#data = pd.read_csv('data_cleaned2.csv',\n",
    "#                   converters={\"preprocessedTags\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")})\n",
    "\n",
    "#data = data[['desc', 'unstemmed_desc', 'preprocessedTags', 'Tag1']].dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.groupby('Tag1').Tag1.transform(len) > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.groupby('Tag1')\n",
    "data = data.apply(lambda x: x.sample(data.size().min())).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>desc</th>\n",
       "      <th>unstemmed_desc</th>\n",
       "      <th>preprocessedTags</th>\n",
       "      <th>Tag1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2214914</td>\n",
       "      <td>net api googl talk net api googl talk look net...</td>\n",
       "      <td>net api google talk net api google talk lookin...</td>\n",
       "      <td>[.net, api, open-source]</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>371851</td>\n",
       "      <td>websit web app architectur advic websit web ap...</td>\n",
       "      <td>website web app architecture advice website we...</td>\n",
       "      <td>[.net, html, css]</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184884</td>\n",
       "      <td>xna game tutori xna game tutori code want lear...</td>\n",
       "      <td>xna game tutorial xna game tutorial coding wan...</td>\n",
       "      <td>[.net]</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3516203</td>\n",
       "      <td>script languag net base ide script languag net...</td>\n",
       "      <td>scripting language net based ide scripting lan...</td>\n",
       "      <td>[.net]</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166744</td>\n",
       "      <td>best linux distribut run mono best linux distr...</td>\n",
       "      <td>best linux distribution running mono best linu...</td>\n",
       "      <td>[.net, linux]</td>\n",
       "      <td>.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6261</th>\n",
       "      <td>25429904</td>\n",
       "      <td>file file creat filesystem f destin anoth e so...</td>\n",
       "      <td>file file created filesystem f destination ano...</td>\n",
       "      <td>[windows]</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6262</th>\n",
       "      <td>33901173</td>\n",
       "      <td>remov certain charact certain file remov certa...</td>\n",
       "      <td>removing certain characters certain file remov...</td>\n",
       "      <td>[windows, batch-file, command-line]</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6263</th>\n",
       "      <td>35541334</td>\n",
       "      <td>oracl mac virtualbox window 10 work oracl mac ...</td>\n",
       "      <td>oracle mac virtualbox windows 10 working oracl...</td>\n",
       "      <td>[windows, oracle, macos]</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6264</th>\n",
       "      <td>8412792</td>\n",
       "      <td>smallest partit smallest partit need creat sma...</td>\n",
       "      <td>smallest partition smallest partition need cre...</td>\n",
       "      <td>[windows, linux]</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>25113066</td>\n",
       "      <td>upload file dropbox upload file dropbox made m...</td>\n",
       "      <td>uploading files dropbox uploading files dropbo...</td>\n",
       "      <td>[windows]</td>\n",
       "      <td>windows</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6266 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id                                               desc  \\\n",
       "0      2214914  net api googl talk net api googl talk look net...   \n",
       "1       371851  websit web app architectur advic websit web ap...   \n",
       "2      2184884  xna game tutori xna game tutori code want lear...   \n",
       "3      3516203  script languag net base ide script languag net...   \n",
       "4       166744  best linux distribut run mono best linux distr...   \n",
       "...        ...                                                ...   \n",
       "6261  25429904  file file creat filesystem f destin anoth e so...   \n",
       "6262  33901173  remov certain charact certain file remov certa...   \n",
       "6263  35541334  oracl mac virtualbox window 10 work oracl mac ...   \n",
       "6264   8412792  smallest partit smallest partit need creat sma...   \n",
       "6265  25113066  upload file dropbox upload file dropbox made m...   \n",
       "\n",
       "                                         unstemmed_desc  \\\n",
       "0     net api google talk net api google talk lookin...   \n",
       "1     website web app architecture advice website we...   \n",
       "2     xna game tutorial xna game tutorial coding wan...   \n",
       "3     scripting language net based ide scripting lan...   \n",
       "4     best linux distribution running mono best linu...   \n",
       "...                                                 ...   \n",
       "6261  file file created filesystem f destination ano...   \n",
       "6262  removing certain characters certain file remov...   \n",
       "6263  oracle mac virtualbox windows 10 working oracl...   \n",
       "6264  smallest partition smallest partition need cre...   \n",
       "6265  uploading files dropbox uploading files dropbo...   \n",
       "\n",
       "                         preprocessedTags     Tag1  \n",
       "0                [.net, api, open-source]     .net  \n",
       "1                       [.net, html, css]     .net  \n",
       "2                                  [.net]     .net  \n",
       "3                                  [.net]     .net  \n",
       "4                           [.net, linux]     .net  \n",
       "...                                   ...      ...  \n",
       "6261                            [windows]  windows  \n",
       "6262  [windows, batch-file, command-line]  windows  \n",
       "6263             [windows, oracle, macos]  windows  \n",
       "6264                     [windows, linux]  windows  \n",
       "6265                            [windows]  windows  \n",
       "\n",
       "[6266 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data['desc']\n",
    "x_unstemmed = data['unstemmed_desc']\n",
    "y = data['preprocessedTags']\n",
    "# y_tag = data['Tag1']\n",
    "mb = MultiLabelBinarizer()\n",
    "y_encoded = mb.fit_transform(y)\n",
    "# y_encoded = mb.fit_transform(y_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_unstemmed,\n",
    "                                                    y_encoded,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer + Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import text\n",
    "\n",
    "max_length = 500\n",
    "\n",
    "tokenizer_t = text.Tokenizer(num_words=max_length)\n",
    "tokenizer_t.fit_on_texts(x_train)\n",
    "\n",
    "bag_of_words_train = tokenizer_t.texts_to_matrix(x_train)\n",
    "bag_of_words_test = tokenizer_t.texts_to_matrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xInput = Input(shape=(max_length))\n",
    "x_ = Dense(500, activation='relu')(xInput)\n",
    "x_ = Dense(500, activation='relu')(x_)\n",
    "output = Dense(len(y_encoded[0]), activation='sigmoid')(x_)\n",
    "\n",
    "model_toke = Model(inputs=xInput, outputs=output, name='Toke')\n",
    "\n",
    "# Compile the model\n",
    "model_toke.compile(loss=CategoricalCrossentropy(from_logits=True, label_smoothing=0.2),\n",
    "                   optimizer=Adam(learning_rate=0.000001),\n",
    "                   metrics=[CategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5,\n",
    "                                         mode='max',\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Toke\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 205)               102705    \n",
      "=================================================================\n",
      "Total params: 603,705\n",
      "Trainable params: 603,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_toke.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "141/141 [==============================] - 1s 4ms/step - loss: 8.7010 - accuracy: 0.0077 - val_loss: 9.1517 - val_accuracy: 0.0100\n",
      "Epoch 2/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.8147 - accuracy: 0.0066 - val_loss: 9.1432 - val_accuracy: 0.0139\n",
      "Epoch 3/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6994 - accuracy: 0.0112 - val_loss: 9.1348 - val_accuracy: 0.0159\n",
      "Epoch 4/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.7568 - accuracy: 0.0119 - val_loss: 9.1263 - val_accuracy: 0.0159\n",
      "Epoch 5/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6458 - accuracy: 0.0123 - val_loss: 9.1179 - val_accuracy: 0.0179\n",
      "Epoch 6/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6248 - accuracy: 0.0143 - val_loss: 9.1094 - val_accuracy: 0.0199\n",
      "Epoch 7/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6568 - accuracy: 0.0166 - val_loss: 9.1009 - val_accuracy: 0.0219\n",
      "Epoch 8/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6964 - accuracy: 0.0166 - val_loss: 9.0924 - val_accuracy: 0.0319\n",
      "Epoch 9/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6609 - accuracy: 0.0227 - val_loss: 9.0839 - val_accuracy: 0.0299\n",
      "Epoch 10/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6748 - accuracy: 0.0225 - val_loss: 9.0753 - val_accuracy: 0.0319\n",
      "Epoch 11/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6870 - accuracy: 0.0251 - val_loss: 9.0667 - val_accuracy: 0.0319\n",
      "Epoch 12/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5980 - accuracy: 0.0302 - val_loss: 9.0580 - val_accuracy: 0.0359\n",
      "Epoch 13/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6444 - accuracy: 0.0317 - val_loss: 9.0491 - val_accuracy: 0.0418\n",
      "Epoch 14/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5675 - accuracy: 0.0335 - val_loss: 9.0402 - val_accuracy: 0.0418\n",
      "Epoch 15/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.7295 - accuracy: 0.0345 - val_loss: 9.0312 - val_accuracy: 0.0458\n",
      "Epoch 16/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5932 - accuracy: 0.0359 - val_loss: 9.0221 - val_accuracy: 0.0458\n",
      "Epoch 17/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6252 - accuracy: 0.0346 - val_loss: 9.0129 - val_accuracy: 0.0458\n",
      "Epoch 18/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5480 - accuracy: 0.0424 - val_loss: 9.0035 - val_accuracy: 0.0438\n",
      "Epoch 19/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6072 - accuracy: 0.0393 - val_loss: 8.9941 - val_accuracy: 0.0458\n",
      "Epoch 20/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5967 - accuracy: 0.0452 - val_loss: 8.9845 - val_accuracy: 0.0478\n",
      "Epoch 21/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6005 - accuracy: 0.0430 - val_loss: 8.9747 - val_accuracy: 0.0518\n",
      "Epoch 22/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6538 - accuracy: 0.0415 - val_loss: 8.9649 - val_accuracy: 0.0518\n",
      "Epoch 23/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5663 - accuracy: 0.0439 - val_loss: 8.9549 - val_accuracy: 0.0538\n",
      "Epoch 24/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5139 - accuracy: 0.0501 - val_loss: 8.9447 - val_accuracy: 0.0538\n",
      "Epoch 25/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.5789 - accuracy: 0.0498 - val_loss: 8.9343 - val_accuracy: 0.0578\n",
      "Epoch 26/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4990 - accuracy: 0.0491 - val_loss: 8.9239 - val_accuracy: 0.0578\n",
      "Epoch 27/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6147 - accuracy: 0.0517 - val_loss: 8.9132 - val_accuracy: 0.0598\n",
      "Epoch 28/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4391 - accuracy: 0.0490 - val_loss: 8.9023 - val_accuracy: 0.0598\n",
      "Epoch 29/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.6410 - accuracy: 0.0575 - val_loss: 8.8913 - val_accuracy: 0.0618\n",
      "Epoch 30/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4699 - accuracy: 0.0562 - val_loss: 8.8801 - val_accuracy: 0.0637\n",
      "Epoch 31/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4107 - accuracy: 0.0587 - val_loss: 8.8687 - val_accuracy: 0.0637\n",
      "Epoch 32/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4548 - accuracy: 0.0567 - val_loss: 8.8571 - val_accuracy: 0.0657\n",
      "Epoch 33/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4329 - accuracy: 0.0545 - val_loss: 8.8452 - val_accuracy: 0.0677\n",
      "Epoch 34/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4703 - accuracy: 0.0670 - val_loss: 8.8332 - val_accuracy: 0.0677\n",
      "Epoch 35/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3884 - accuracy: 0.0573 - val_loss: 8.8210 - val_accuracy: 0.0697\n",
      "Epoch 36/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.4111 - accuracy: 0.0676 - val_loss: 8.8085 - val_accuracy: 0.0717\n",
      "Epoch 37/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3524 - accuracy: 0.0667 - val_loss: 8.7958 - val_accuracy: 0.0737\n",
      "Epoch 38/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3189 - accuracy: 0.0690 - val_loss: 8.7830 - val_accuracy: 0.0757\n",
      "Epoch 39/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3532 - accuracy: 0.0813 - val_loss: 8.7700 - val_accuracy: 0.0757\n",
      "Epoch 40/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3254 - accuracy: 0.0744 - val_loss: 8.7568 - val_accuracy: 0.0797\n",
      "Epoch 41/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3922 - accuracy: 0.0754 - val_loss: 8.7433 - val_accuracy: 0.0797\n",
      "Epoch 42/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3090 - accuracy: 0.0756 - val_loss: 8.7297 - val_accuracy: 0.0797\n",
      "Epoch 43/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.3269 - accuracy: 0.0769 - val_loss: 8.7159 - val_accuracy: 0.0837\n",
      "Epoch 44/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2848 - accuracy: 0.0771 - val_loss: 8.7019 - val_accuracy: 0.0876\n",
      "Epoch 45/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2375 - accuracy: 0.0791 - val_loss: 8.6877 - val_accuracy: 0.0876\n",
      "Epoch 46/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2512 - accuracy: 0.0783 - val_loss: 8.6733 - val_accuracy: 0.0896\n",
      "Epoch 47/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2288 - accuracy: 0.0864 - val_loss: 8.6588 - val_accuracy: 0.0896\n",
      "Epoch 48/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1367 - accuracy: 0.0903 - val_loss: 8.6441 - val_accuracy: 0.0896\n",
      "Epoch 49/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2311 - accuracy: 0.0876 - val_loss: 8.6292 - val_accuracy: 0.0916\n",
      "Epoch 50/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1912 - accuracy: 0.1000 - val_loss: 8.6142 - val_accuracy: 0.0936\n",
      "Epoch 51/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1607 - accuracy: 0.0908 - val_loss: 8.5991 - val_accuracy: 0.0976\n",
      "Epoch 52/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1871 - accuracy: 0.0931 - val_loss: 8.5838 - val_accuracy: 0.0976\n",
      "Epoch 53/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.2354 - accuracy: 0.0969 - val_loss: 8.5684 - val_accuracy: 0.0996\n",
      "Epoch 54/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0607 - accuracy: 0.1070 - val_loss: 8.5528 - val_accuracy: 0.1036\n",
      "Epoch 55/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1848 - accuracy: 0.1044 - val_loss: 8.5373 - val_accuracy: 0.1076\n",
      "Epoch 56/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0934 - accuracy: 0.1105 - val_loss: 8.5216 - val_accuracy: 0.1116\n",
      "Epoch 57/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.1183 - accuracy: 0.1083 - val_loss: 8.5059 - val_accuracy: 0.1116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0457 - accuracy: 0.1154 - val_loss: 8.4901 - val_accuracy: 0.1175\n",
      "Epoch 59/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0814 - accuracy: 0.1239 - val_loss: 8.4743 - val_accuracy: 0.1175\n",
      "Epoch 60/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0229 - accuracy: 0.1133 - val_loss: 8.4585 - val_accuracy: 0.1195\n",
      "Epoch 61/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0556 - accuracy: 0.1109 - val_loss: 8.4427 - val_accuracy: 0.1195\n",
      "Epoch 62/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.9964 - accuracy: 0.1208 - val_loss: 8.4268 - val_accuracy: 0.1195\n",
      "Epoch 63/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0800 - accuracy: 0.1156 - val_loss: 8.4109 - val_accuracy: 0.1195\n",
      "Epoch 64/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.9695 - accuracy: 0.1167 - val_loss: 8.3952 - val_accuracy: 0.1195\n",
      "Epoch 65/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0031 - accuracy: 0.1338 - val_loss: 8.3794 - val_accuracy: 0.1215\n",
      "Epoch 66/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.9990 - accuracy: 0.1281 - val_loss: 8.3638 - val_accuracy: 0.1215\n",
      "Epoch 67/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 8.0020 - accuracy: 0.1361 - val_loss: 8.3482 - val_accuracy: 0.1235\n",
      "Epoch 68/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.8957 - accuracy: 0.1327 - val_loss: 8.3328 - val_accuracy: 0.1255\n",
      "Epoch 69/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.9191 - accuracy: 0.1397 - val_loss: 8.3174 - val_accuracy: 0.1255\n",
      "Epoch 70/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.8322 - accuracy: 0.1458 - val_loss: 8.3023 - val_accuracy: 0.1295\n",
      "Epoch 71/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.8754 - accuracy: 0.1369 - val_loss: 8.2873 - val_accuracy: 0.1295\n",
      "Epoch 72/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.9226 - accuracy: 0.1445 - val_loss: 8.2725 - val_accuracy: 0.1315\n",
      "Epoch 73/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.8466 - accuracy: 0.1432 - val_loss: 8.2579 - val_accuracy: 0.1355\n",
      "Epoch 74/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.8338 - accuracy: 0.1434 - val_loss: 8.2435 - val_accuracy: 0.1375\n",
      "Epoch 75/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6758 - accuracy: 0.1568 - val_loss: 8.2292 - val_accuracy: 0.1394\n",
      "Epoch 76/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7504 - accuracy: 0.1704 - val_loss: 8.2153 - val_accuracy: 0.1414\n",
      "Epoch 77/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7272 - accuracy: 0.1480 - val_loss: 8.2017 - val_accuracy: 0.1414\n",
      "Epoch 78/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7202 - accuracy: 0.1452 - val_loss: 8.1883 - val_accuracy: 0.1434\n",
      "Epoch 79/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6899 - accuracy: 0.1527 - val_loss: 8.1752 - val_accuracy: 0.1414\n",
      "Epoch 80/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6383 - accuracy: 0.1657 - val_loss: 8.1625 - val_accuracy: 0.1454\n",
      "Epoch 81/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7057 - accuracy: 0.1550 - val_loss: 8.1500 - val_accuracy: 0.1434\n",
      "Epoch 82/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7056 - accuracy: 0.1606 - val_loss: 8.1379 - val_accuracy: 0.1434\n",
      "Epoch 83/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6361 - accuracy: 0.1742 - val_loss: 8.1262 - val_accuracy: 0.1454\n",
      "Epoch 84/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6705 - accuracy: 0.1578 - val_loss: 8.1148 - val_accuracy: 0.1454\n",
      "Epoch 85/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6533 - accuracy: 0.1595 - val_loss: 8.1037 - val_accuracy: 0.1494\n",
      "Epoch 86/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6471 - accuracy: 0.1623 - val_loss: 8.0930 - val_accuracy: 0.1474\n",
      "Epoch 87/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6652 - accuracy: 0.1643 - val_loss: 8.0827 - val_accuracy: 0.1494\n",
      "Epoch 88/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.7178 - accuracy: 0.1563 - val_loss: 8.0728 - val_accuracy: 0.1494\n",
      "Epoch 89/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.6417 - accuracy: 0.1533 - val_loss: 8.0632 - val_accuracy: 0.1474\n",
      "Epoch 90/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 7.5667 - accuracy: 0.1562 - val_loss: 8.0540 - val_accuracy: 0.1474\n",
      "INFO:tensorflow:Assets written to: /home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/assets\n"
     ]
    }
   ],
   "source": [
    "# Load the model, if does not exist then train one\n",
    "if globalStrategy == 'retrain' or globalStrategy == 'retrainToke':\n",
    "    epochs = epochs\n",
    "    batch_size=batch_size\n",
    "    history = model_toke.fit(bag_of_words_train, y_train,\n",
    "                             epochs=epochs,\n",
    "                             validation_split=0.1,\n",
    "                             callbacks=[callback],\n",
    "                             verbose=1)\n",
    "\n",
    "    model_toke.save('/home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/')\n",
    "    model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/')\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/')\n",
    "    except OSError:\n",
    "        epochs = epochs\n",
    "        batch_size = batch_size\n",
    "        history = model_toke.fit(bag_of_words_train, y_train,\n",
    "                                 epochs=epochs,\n",
    "                                 validation_split=0.1,\n",
    "                                 callbacks=[callback],\n",
    "                                 verbose=1)\n",
    "\n",
    "        model_toke.save('/home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/')\n",
    "        model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/SimpleTokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 7.6107 - accuracy: 0.1380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.610741138458252, 0.13795852661132812]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_toke.evaluate(bag_of_words_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>Jaccard_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.106168</td>\n",
       "      <td>0.05606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  F1_micro  Jaccard_micro\n",
       "51       0.81  0.106168        0.05606"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_toke.predict(bag_of_words_test)\n",
    "#predict_ = np.where(predict > 0.98, 1, 0)\n",
    "scoring(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74313533, 0.3654136 , 0.5684666 , 0.5244302 , 0.65976286,\n",
       "       0.41830975, 0.437737  , 0.36241424, 0.5013205 , 0.4975043 ,\n",
       "       0.52363724, 0.39109153, 0.40014058, 0.612706  , 0.7281524 ,\n",
       "       0.5659703 , 0.42216212, 0.36713135, 0.74554884, 0.45231068,\n",
       "       0.35666895, 0.7056698 , 0.6885657 , 0.70913434, 0.36504552,\n",
       "       0.553618  , 0.5204188 , 0.54793274, 0.51010895, 0.42141083,\n",
       "       0.45259464, 0.48266152, 0.45075354, 0.47270927, 0.74714434,\n",
       "       0.46310806, 0.4334555 , 0.5502271 , 0.537752  , 0.536212  ,\n",
       "       0.5222036 , 0.5166796 , 0.45106396, 0.47247455, 0.44078785,\n",
       "       0.40066326, 0.44969013, 0.5308471 , 0.4176167 , 0.5237626 ,\n",
       "       0.441598  , 0.4753249 , 0.3969262 , 0.38052827, 0.40066883,\n",
       "       0.42699608, 0.43161687, 0.53866893, 0.54916024, 0.4401371 ,\n",
       "       0.3632746 , 0.4749255 , 0.4986868 , 0.44291022, 0.40933096,\n",
       "       0.5051384 , 0.52244663, 0.4206973 , 0.7399657 , 0.5653693 ,\n",
       "       0.38986912, 0.39922598, 0.4645747 , 0.7615176 , 0.42001608,\n",
       "       0.48420435, 0.567684  , 0.5116083 , 0.36685115, 0.45252255,\n",
       "       0.34271312, 0.4525168 , 0.74090415, 0.4596008 , 0.6485935 ,\n",
       "       0.4071743 , 0.67702615, 0.41447186, 0.75236726, 0.41438898,\n",
       "       0.7561338 , 0.43208697, 0.5419067 , 0.45951343, 0.40246803,\n",
       "       0.46967843, 0.38225642, 0.45944282, 0.47417045, 0.6849647 ,\n",
       "       0.4735798 , 0.43410993, 0.36446854, 0.56228036, 0.45898077,\n",
       "       0.42371467, 0.4329243 , 0.39047307, 0.34487084, 0.5000842 ,\n",
       "       0.39891022, 0.3734292 , 0.43478015, 0.42581305, 0.4943603 ,\n",
       "       0.7111684 , 0.4273672 , 0.46630165, 0.45832857, 0.40636092,\n",
       "       0.38034743, 0.53847003, 0.77295905, 0.47863233, 0.5604808 ,\n",
       "       0.377027  , 0.468     , 0.4709513 , 0.42406175, 0.5947168 ,\n",
       "       0.49193653, 0.3865117 , 0.56840014, 0.5792505 , 0.7035973 ,\n",
       "       0.51230353, 0.5373379 , 0.43954155, 0.3708778 , 0.51197433,\n",
       "       0.75255364, 0.5001323 , 0.5418109 , 0.4437845 , 0.6179175 ,\n",
       "       0.5011357 , 0.41253424, 0.39281106, 0.6949922 , 0.5184177 ,\n",
       "       0.8034628 , 0.7232604 , 0.376234  , 0.39146113, 0.3945045 ,\n",
       "       0.51670736, 0.32019156, 0.40708038, 0.6765033 , 0.43247828,\n",
       "       0.56447774, 0.33872607, 0.41703612, 0.7145887 , 0.5995374 ,\n",
       "       0.45707685, 0.49570802, 0.61582065, 0.30934417, 0.43224892,\n",
       "       0.5312163 , 0.4460013 , 0.5424857 , 0.44409472, 0.42237025,\n",
       "       0.42723587, 0.32736474, 0.37750182, 0.5310815 , 0.41685322,\n",
       "       0.38055798, 0.44613683, 0.52196324, 0.41622815, 0.5034956 ,\n",
       "       0.45600775, 0.52426976, 0.49845058, 0.37353137, 0.49509257,\n",
       "       0.45121557, 0.5119781 , 0.52968025, 0.46402353, 0.4454382 ,\n",
       "       0.50026053, 0.47725716, 0.5225318 , 0.49588084, 0.692601  ,\n",
       "       0.58381927, 0.4477459 , 0.54835063, 0.6262882 , 0.4370404 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFOpenAIGPTModel.\n",
      "\n",
      "All the layers of TFOpenAIGPTModel were initialized from the model checkpoint at openai-gpt.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFOpenAIGPTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "\n",
    "# set token for padding\n",
    "tokenizer.pad_token = 0\n",
    "\n",
    "# Load model\n",
    "model = TFOpenAIGPTModel.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready output data for the model\n",
    "max_length=250\n",
    "\n",
    "x_train_toke = tokenizer(text=x_train.to_list(),\n",
    "                         add_special_tokens=True,\n",
    "                         max_length=max_length,\n",
    "                         truncation=True,\n",
    "                         padding=True, \n",
    "                         return_tensors='tf',\n",
    "                         return_token_type_ids=False,\n",
    "                         return_attention_mask=False,\n",
    "                         verbose=True)\n",
    "\n",
    "x_test_toke = tokenizer(text=x_test.to_list(),\n",
    "                        add_special_tokens=True,\n",
    "                        max_length=max_length,\n",
    "                        truncation=True,\n",
    "                        padding=True,\n",
    "                        return_tensors='tf',\n",
    "                        return_token_type_ids=False,\n",
    "                        return_attention_mask=False,\n",
    "                        verbose=True)\n",
    "\n",
    "x_train_toke = x_train_toke['input_ids']\n",
    "x_test_toke = x_test_toke['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "xInput = Input(shape=(max_length))\n",
    "x_ = Dense(500, activation='relu')(xInput)\n",
    "x_ = Dense(500, activation='relu')(x_)\n",
    "output = Dense(len(y_encoded[0]), activation='sigmoid')(x_)\n",
    "\n",
    "model_toke = Model(inputs=xInput, outputs=output, name='Toke')\n",
    "\n",
    "# Compile the model\n",
    "model_toke.compile(loss=CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "                   optimizer=Adam(learning_rate=0.0000001),\n",
    "                   metrics=[CategoricalAccuracy('accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5,\n",
    "                                         mode='max',\n",
    "                                         restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Toke\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 250)]             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 500)               125500    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 205)               102705    \n",
      "=================================================================\n",
      "Total params: 478,705\n",
      "Trainable params: 478,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_toke.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "141/141 [==============================] - 1s 3ms/step - loss: 11556.8717 - accuracy: 0.0078 - val_loss: 12165.6162 - val_accuracy: 0.0100\n",
      "Epoch 2/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 11781.8260 - accuracy: 0.0090 - val_loss: 12095.4658 - val_accuracy: 0.0100\n",
      "Epoch 3/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 11564.0303 - accuracy: 0.0083 - val_loss: 12026.4941 - val_accuracy: 0.0100\n",
      "Epoch 4/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 11741.9377 - accuracy: 0.0087 - val_loss: 11958.7705 - val_accuracy: 0.0100\n",
      "Epoch 5/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 11421.5640 - accuracy: 0.0108 - val_loss: 11892.5635 - val_accuracy: 0.0100\n",
      "Epoch 6/200\n",
      "141/141 [==============================] - 0s 2ms/step - loss: 11378.1659 - accuracy: 0.0095 - val_loss: 11826.9531 - val_accuracy: 0.0100\n",
      "INFO:tensorflow:Assets written to: /home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/assets\n"
     ]
    }
   ],
   "source": [
    "# Load the model, if does not exist then train one\n",
    "if globalStrategy == 'retrain' or globalStrategy == 'retrainToke':\n",
    "    epochs = epochs\n",
    "    batch_size=batch_size\n",
    "    history = model_toke.fit(x_train_toke, y_train,\n",
    "                             epochs=epochs,\n",
    "                             validation_split=0.1,\n",
    "                             callbacks=[callback],\n",
    "                             verbose=1)\n",
    "\n",
    "    model_toke.save('/home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/')\n",
    "    model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/')\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/')\n",
    "    except OSError:\n",
    "        epochs = epochs\n",
    "        batch_size = batch_size\n",
    "        history = model_toke.fit(x_train_toke, y_train,\n",
    "                                 epochs=epochs,\n",
    "                                 validation_split=0.1,\n",
    "                                 callbacks=[callback],\n",
    "                                 verbose=1)\n",
    "\n",
    "        model_toke.save('/home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/')\n",
    "        model_toke = tf.keras.models.load_model('/home/mlmaster/Code/Ing_ml_P7/GPTTokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 1ms/step - loss: 11520.4561 - accuracy: 0.0072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11520.4560546875, 0.007177033461630344]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_toke.evaluate(x_test_toke, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>F1_micro</th>\n",
       "      <th>Jaccard_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.01942</td>\n",
       "      <td>0.009805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  F1_micro  Jaccard_micro\n",
       "67       0.97   0.01942       0.009805"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model_toke.predict(x_test_toke)\n",
    "#predict_ = np.where(predict > 0.98, 1, 0)\n",
    "scoring(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.3911589e-34,\n",
       "       1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "       1.0000000e+00, 1.0000000e+00, 1.0000000e+00, 1.0000000e+00,\n",
       "       0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "       0.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
